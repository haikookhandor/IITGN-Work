# -*- coding: utf-8 -*-
"""Q2_test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R-h6mR7sy_h7Yi1dKE4xCb8nKprgkVDj
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import time
import statistics
from linearRegression.linear_regression import LinearRegression
from linearRegression.metrics import *

np.random.seed(0)

N = 90
P = 10
X = pd.DataFrame(np.random.randn(N, P))
y = pd.Series(np.random.randn(N))


# Varying the penalty, size, gradient type
i = 0
values={}
for gradient_type in ('manual','jax'):
    min_rmse = np.inf
    min_size = 0
    min_lr = 0
    min_alpha = 0
    gradient = 'random'
    min_penalty = "random"
    for penalty in ('unregularized','l1','l2'):
        for size in (1,24,36,48):
            for lr in (0.01,0.001,0.03,0.003):
                for alpha in (10,1,0.1,0.01):
                    # print('Batch Gradient Descent with ',gradient_type,' gradient computation for ',penalty,' objective : ',size)
                    if(penalty!='l1' or gradient_type!='manual'):
                        start_time = time.time()
                        LR = LinearRegression(fit_intercept=True)
                        LR.fit_gradient_descent(X,y,size,alpha,gradient_type,penalty,lr=lr)
                        y_hat = LR.predict(X)
                        end_time = time.time() 
                        time_taken = end_time - start_time
                        i+=1
                        print(f'{i}     {gradient_type}     {penalty}       {size}          {lr}      {alpha}       {rmse(y_hat, y)}        {mae(y_hat, y)}     {time_taken}')
                        if(rmse(y_hat, y)<min_rmse):
                            min_rmse = rmse(y_hat, y)
                            min_size = size
                            min_lr = lr
                            min_penalty = penalty
                            gradient = gradient_type
                            min_alpha = alpha
    values[gradient] = [min_penalty,min_size,min_lr,min_rmse,min_alpha]
    

for value in values:
    print(value,values[value])

# Varying the penalty, size, gradient type for SGD

i = 0
values={}
min_rmse = np.inf
min_size = 0
min_lr = 0
min_alpha = 0
min_penalty = "random"
for penalty in ('unregularized','l2'):
        for lr in (0.01,0.001,0.03,0.003):
            for alpha in (10,1,0.1,0.01):
                for momentum in (0.1,0.3,0.5,0.7):
                # print('Batch Gradient Descent with ',gradient_type,' gradient computation for ',penalty,' objective : ',size)
                    start_time = time.time()
                    LR = LinearRegression(fit_intercept=True)
                    LR.fit_SGD_with_momentum(X,y,penalty,alpha = alpha,lr = lr,momentum = momentum)
                    y_hat = LR.predict(X)
                    end_time = time.time()
                    time_taken = end_time - start_time
                    i+=1
                    print(f'{i}     {penalty}         {lr}      {alpha}       {momentum}        {rmse(y_hat, y)}        {mae(y_hat, y)}     {time_taken}')
                    if(rmse(y_hat, y)<min_rmse):
                        min_rmse = rmse(y_hat, y)
                        min_lr = lr
                        min_penalty = penalty
                        min_alpha = alpha
                        min_momentum = momentum

values['sgd'] = [min_penalty,min_lr,min_alpha, min_momentum, min_rmse]

for value in values:
    print(value,values[value])
                    
